# IPAS: Integrated persistent archive solution

## Introduction
Reliability is one of the top priorities in any data storage solution. To achieve satisfactory reliabilities often means to have multiple copies of the same data on different storage media on different physical premise. Current popular consumer-grade storage redundancy solutions were most likely exclusively local (like Apple's Time Machine, or your external hard drive) or strictly remote (like Goole Drive, One Drive, DropBox, etc.). Local storage redundancy solution provides high level of availability, but risks dying with live data if in a single physical catastrophe like a house hire; remote storage redundancy solution provides high level of reliability, but can provide limited availability. The latter problem was particularly serious since for one, consumer-grade internet service is severely capped in upload bandwidth (my download speed is 100Mbps but my upload speed is only 5 Mbps); as a result, uploading a single large file can be challenging, especially if internet outage could happen intermittently, which could completely destroy any upload progress. Finally, I simply don't have the luxury of keeping my laptop running on my home network all the time, since I need to bring it to work, to school, or other occasions that might disrupt the upload process and cause me to lose progress on a large upload.

This project would provide an integrated solution that contains a local storage solution for availability, a remote storage solution for reliabilitiy, and a file upload process that is resistant against intermittent internet outage (or other types of disruption like power outage).

## Tech stack
A Raspberry Pi will be used to host code base. I will use Django 3 for providing GUI and entrypoint for end user, use AWS S3 (and Python's `boto3`) for storage backup, and Python for the file upload/download daemon. I am considering dockerizing the entire project for deployment to increase compatibility, but I have not decided yet.